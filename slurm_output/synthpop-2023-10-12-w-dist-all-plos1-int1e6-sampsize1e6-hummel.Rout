
R version 4.4.0 (2024-04-24) -- "Puppy Cup"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

- Project '/oscar/home/akhann16/code/net-ergm-v4plus' loaded. [renv 1.0.7]
> # Analyze synthetic dataset with 32K nodes 
> 
> # Fit ERGM with 5 dyadic independent terms
> 
> rm(list=ls())
> 
> # Activate R environment ------------------------------
> 
> library(renv)

Attaching package: ‘renv’

The following objects are masked from ‘package:stats’:

    embed, update

The following objects are masked from ‘package:utils’:

    history, upgrade

The following objects are masked from ‘package:base’:

    autoload, load, remove, use

> renv::activate()
> 
> 
> # Libraries ----------
> 
> library(network)

‘network’ 1.18.2 (2023-12-04), part of the Statnet Project
* ‘news(package="network")’ for changes since last version
* ‘citation("network")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

> library(ergm)

‘ergm’ 4.6.0 (2023-12-17), part of the Statnet Project
* ‘news(package="ergm")’ for changes since last version
* ‘citation("ergm")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

‘ergm’ 4 is a major update that introduces some backwards-incompatible
changes. Please type ‘news(package="ergm")’ for a list of major
changes.

> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(ergm.userterms)
Loading required package: statnet.common

Attaching package: ‘statnet.common’

The following objects are masked from ‘package:base’:

    attr, order


‘ergm.userterms’ 3.1.1 (2020-02-01), part of the Statnet Project
* ‘news(package="ergm.userterms")’ for changes since last version
* ‘citation("ergm.userterms")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

NOTE: If you use custom ERGM terms based on ‘ergm.userterms’ version
prior to 3.1, you will need to perform a one-time update of the package
boilerplate files (the files that you did not write or modify) from
‘ergm.userterms’ 3.1 or later. See help('eut-upgrade') for
instructions.

> library(here)
here() starts at /oscar/home/akhann16/code/net-ergm-v4plus
> 
> 
> # Read Synthpop Data ------------------------------ 
> 
> data_path <- here("data", "synthpop-2023-10-12 12_01_32.csv")
> data <- read.csv(data_path, header=TRUE)
> glimpse(data)
Rows: 32,002
Columns: 15
$ sex                       <chr> "M", "M", "M", "M", "M", "M", "M", "M", "M",…
$ race                      <chr> "Wh", "Wh", "Wh", "Wh", "Wh", "Wh", "Wh", "W…
$ agecat                    <chr> "18-24", "18-24", "18-24", "18-24", "18-24",…
$ age_started               <int> 18, 19, 16, 19, 5, 19, 15, 17, 25, 18, 21, 1…
$ fraction_recept_sharing   <dbl> 1.00, 0.10, 0.10, 0.00, 0.00, 0.00, 0.25, 0.…
$ syringe_source            <int> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,…
$ daily_injection_intensity <chr> "once or twice a day", "once or twice a day"…
$ age_lb                    <int> 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, …
$ age_ub                    <int> 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, …
$ age                       <int> 23, 21, 19, 20, 21, 21, 21, 21, 25, 18, 24, …
$ zipcode                   <int> 60644, 60644, 60644, 60644, 60644, 60644, 60…
$ Zip                       <int> 60644, 60644, 60644, 60644, 60644, 60644, 60…
$ lon                       <dbl> -87.76885, -87.77289, -87.76898, -87.76998, …
$ lat                       <dbl> 41.88311, 41.88240, 41.86867, 41.89144, 41.8…
$ hcv_status                <chr> "sucseptible", "sucseptible", "sucseptible",…
> 
> # Input  In/Outdegree Data ------------------------------
> # (from networks simulated form the fit, as an alternate source of targets)
> 
> inedges <- read.csv(here("data", "pplrss.csv")) #in- and out-edges
> outedges <- read.csv(here("data", "ppldss.csv"))
> negbin_indeg <- read.csv(here("data", "negbin-indeg.csv"))
> negbin_outdeg <- read.csv(here("data", "negbin-outdeg.csv"))
> inedges.data <- read.csv(file = here("data", "inedges_data.csv"), header = TRUE)
> outedges.data <- read.csv(file = here("data", "outedges_data.csv"), header = TRUE)
> 
> # Input  Degree Distribution Data ------------------------------
> 
> #degree_distribution_target_stats <- 
>  # readRDS(here("simulate-from-ergms/out/degree_distribution_target_stats.RDS"))
> #names(degree_distribution_target_stats)
> 
>  
> 
> # Initialize network ----------
> 
> n <- nrow(data)
> n0 <- network.initialize(n = n, directed = TRUE)
> 
> 
> # Compute target number of edges ----------
> 
> inedges_target <- sum(inedges.data$k * inedges.data$nbprob * n)
> outedges_target <- sum(outedges.data$k * outedges.data$nbprob * n)
> edges_target <- mean(c(inedges_target, outedges_target))
> 
> 
> 
> 
> # Assign vertex attributes to the network ----------
> 
> synthpop_cols <- colnames(data)
> set.vertex.attribute(n0, colnames(data), data)
> 
> 
> # Test assignment between `n0` vertex attributes and `synthpop_cols` ----------
> 
> ## For sex variable
> identical(n0%v%"sex", data$sex)
[1] TRUE
> table(n0%v%"sex", exclude=NULL)

    F     M 
12573 19429 
> 
> ## For all variables:
> ### get vertex attribute names from the n0 graph object
> vertex_attr_names <- list.vertex.attributes(n0)
> 
> # define a function to check if a vertex attribute is identical to the corresponding column in data
> check_identical <- function(attr_name) {
+   graph_attr <- n0 %v% attr_name
+   data_attr <- data[[attr_name]]
+   
+   return(identical(graph_attr, data_attr))
+ }
> 
> ### use sapply() to apply the check_identical() function to all vertex attribute names
> identical_results <- sapply(vertex_attr_names, check_identical)
> 
> ### print the results
> print(identical_results)
                      age                    age_lb               age_started 
                     TRUE                      TRUE                      TRUE 
                   age_ub                    agecat daily_injection_intensity 
                     TRUE                      TRUE                      TRUE 
  fraction_recept_sharing                hcv_status                       lat 
                     TRUE                      TRUE                      TRUE 
                      lon                        na                      race 
                     TRUE                     FALSE                      TRUE 
                      sex            syringe_source              vertex.names 
                     TRUE                      TRUE                     FALSE 
                      Zip                   zipcode 
                     TRUE                      TRUE 
> 
> ### check if any values other than 'vertex.names' are FALSE
> if (any(identical_results[!(names(identical_results) %in% c("vertex.names", "na"))] == FALSE)) {
+   stop("Error: Some vertex attributes do not match the corresponding columns in data.")
+ } else {
+   cat("Test passed: All relevant vertex attributes match the corresponding columns in data.\n")
+ }
Test passed: All relevant vertex attributes match the corresponding columns in data.
> 
> 
> # Recode to add new variables to dataset ------------------------------
> 
> # young (< 26, to be set = 1) vs old (>= 26, to be set = 0) 
> age.cat <- n0 %v% "age"
> age.cat.df <- as.data.frame(age.cat)
> age.cat.df <-  
+   mutate(age.cat, young = ifelse(age.cat <26, 1, 0), .data = age.cat.df)
> xtabs(~age.cat+young, data = age.cat.df)
       young
age.cat    0    1
     18    0  471
     19    0  695
     20    0  854
     21    0 1053
     22    0 1142
     23    0 1286
     24    0 1561
     25    0  739
     26  787    0
     27  910    0
     28  946    0
     29 1018    0
     30 1024    0
     31 1027    0
     32 1119    0
     33 1110    0
     34 1117    0
     35  576    0
     36  585    0
     37  584    0
     38  617    0
     39  611    0
     40  676    0
     41  670    0
     42  732    0
     43  727    0
     44  719    0
     45  240    0
     46  232    0
     47  261    0
     48  253    0
     49  238    0
     50  225    0
     51  228    0
     52  233    0
     53  250    0
     54  235    0
     55  224    0
     56  231    0
     57  225    0
     58  269    0
     59  230    0
     60  258    0
     61  238    0
     62  245    0
     63  251    0
     64  252    0
     65  253    0
     66  212    0
     67  258    0
     68  231    0
     69  238    0
     70  229    0
     71  235    0
     72  219    0
     73  243    0
     74  263    0
     75  271    0
     76  243    0
     77  213    0
     78  256    0
     79  240    0
     80  224    0
> 
> # recode race variable to set ordering of categories
> race <- n0 %v% "race"
> race.num <- recode(race, 
+                    Wh = 1, Bl = 2,
+                    Hi = 3, Ot = 4)
> 
> # Initialize network and add attributes ----------
> 
> n0 %v% "young" <- age.cat.df$young
> n0 %v% "race.num" <- race.num
> 
> 
> # Generate target statistics from meta-mixing data ----------
> 
> ## gender 
> ### mixing information from meta-analysis of sathcap AND socnet
> edges.male.end <- mean(c(0.58, 0.59))
> edges.female.end <- mean(c(0.40, 0.41))
> 
> male.pctmale <- 0.53 
> male.pctfemale <- 0.47
> female.pctmale <- 0.75
> female.pctfemale <- 0.22
> 
> ### set gender targets 
> tgt.male.pctmale <- edges_target*edges.male.end*male.pctmale
> tgt.male.pctfemale <- edges_target*edges.male.end*male.pctfemale
> tgt.female.pctmale <- edges_target*edges.female.end*female.pctmale  
> tgt.female.pctfemale <- edges_target*edges.female.end*female.pctfemale
> 
> ## young (1=young; 0=old)
> ### mixing information from meta-analysis of sathcap AND socnet
> edges.young.end <- 0.10
> edges.old.end <- 0.90
>   
> young.pctyoung <- 0.60
> young.pctold <- 0.40
> old.pctyoung <- 0.14
> old.pctold <- 0.86
>  
> ## set young targets from meta data
> tgt.young.pctyoung <- edges_target * edges.young.end * young.pctyoung
> tgt.young.pctold <- edges_target * edges.young.end * young.pctold
> tgt.old.pctyoung <- edges_target * edges.old.end * old.pctyoung
> tgt.old.pctold <- edges_target * edges.old.end * old.pctold
> 
> 
> ## chicago
> ### mixing information from meta-analysis of sathcap AND socnet
> 
> edges.chicago.end <- 0.87
> edges.nonchicago.end <- 0.13
> 
> chicago.pctchicago <- 0.67
> chicago.pctnonchicago <- 0.30
> nonchicago.pctchicago <- 0.60
> nonchicago.pctnonchicago <- 0.40
> 
> 
> # ### mixing from simulation
> # chicago.mm <- mixingmatrix(sim, "chicago") #fem=1, chicago=2
> # from.nonchicago <- sum(chicago.mm$matrix[,1])
> # from.chicago <- sum(chicago.mm$matrix[,2])
> # 
> # ### set chicago targets from sathcap
> # tgt.chicago.pctchicago <- from.chicago*chicago.pctchicago
> # tgt.chicago.pctnonchicago <- from.chicago*chicago.pctnonchicago
> # tgt.nonchicago.pctchicago <- from.nonchicago*chicago.pctchicago
> # tgt.nonchicago.pctnonchicago <- from.nonchicago*chicago.pctnonchicago
> 
> 
> ## race (1=Black, 2=hispani,3=other, 4=white)
> 
> table(n0 %v% "race.num", exclude=NULL) # will be sorted as per 1=W, 2=B, 3=H, 4=O

    1     2     3     4 
15403  8317  6853  1429 
> 
> pct_to_white	<- mean(c(0.30, 0.31))
> pct_to_black	<- mean(c(0.41,	0.42))
> pct_to_hispanic	<- mean(c(0.21, 0.22))
> pct_to_other	<- mean(c(0.04,	0.05))
> 
> race.w.w <- 0.73
> race.b.w <- 0.10
> race.h.w <- 0.12
> race.o.w <- 0.04
> race.w.b <- 0.10
> race.b.b <- 0.83
> race.h.b <- 0.06
> race.o.b <- 0.01
> race.w.h <- 0.21
> race.b.h <- 0.15
> race.h.h <- 0.62
> race.o.h <- 0.02
> race.w.o <- 0.43
> race.b.o <- 0.21
> race.h.o <- 0.22
> race.o.o <- 0.14
> 
> target.w.w <- edges_target * pct_to_white * race.w.w
> target.b.w <- edges_target * pct_to_white * race.b.w
> target.h.w <- edges_target * pct_to_white * race.h.w
> target.o.w <- edges_target * pct_to_white * race.o.w
> 
> target.w.b <- edges_target * pct_to_black * race.w.b
> target.b.b <- edges_target * pct_to_black * race.b.b
> target.h.b <- edges_target * pct_to_black * race.h.b
> target.o.b <- edges_target * pct_to_black * race.o.b
> 
> target.w.h <- edges_target * pct_to_hispanic * race.w.h
> target.b.h <- edges_target * pct_to_hispanic * race.b.h
> target.h.h <- edges_target * pct_to_hispanic * race.h.h
> target.o.h <- edges_target * pct_to_hispanic * race.o.h
> 
> target.w.o <- edges_target * pct_to_other * race.w.o
> target.b.o <- edges_target * pct_to_other * race.b.o
> target.h.o <- edges_target * pct_to_other * race.h.o
> target.o.o <- edges_target * pct_to_other * race.o.o
> 
> ## degree distributions
> inedges <- inedges %>% 
+   mutate(n_nodes = n*nbprob)
> outedges <- outedges %>% 
+   mutate(n_nodes = n*nbprob)
> 
> negbin_inedges <- negbin_indeg %>% 
+   mutate(n_nodes = n*nbprob)
> negbin_outedges <- negbin_outdeg %>% 
+   mutate(n_nodes = n*nbprob)
> 
> ## distance term
> 
> dist.prop.distribution <- c(15.7, 35.1, 24.1, 22)/100
> dist.nedge.distribution <- edges_target*dist.prop.distribution
> 
> # Fit ERGM (with SATHCAP mixing) ----------
> 
> deg.terms <- 0:3
> indeg.terms <- 0:1  
> 
> dist.terms <- 1:3 #fourth is left out
> #dist.terms <- 3 #only try the third term
> 
> # Specify initial coefs ----------
> 
> edges <- -9.319 
> mix.race.num.4.1  <- 0.16349
> odegree0 <- -0.1386842 
> mix.race.num.2.4 <- 0.13625
> mix.race.num.4.4 <- 0.20408 
> 
> initial_coeffs <- c("edges" = -9.319, 
+                     "mix.race.num.4.1" = 0.16349, 
+                     "odegree0" = -0.1386842, 
+                     "mix.race.num.2.4" = 0.13625, 
+                     "mix.race.num.4.4" = 0.20408)
> 
> fit.metadata.mixing <-
+   ergm(
+     n0 ~
+       edges + 
+       nodemix("sex", levels2=-1)+
+       nodemix("young", levels2=-1)+
+       nodemix("race.num", levels2=-1)+
+       idegree(indeg.terms)+
+       odegree(deg.terms)+
+       dist(dist.terms),
+     target.stats = 
+     c(
+       edges_target,
+       c(tgt.female.pctmale, tgt.male.pctfemale, tgt.male.pctmale),           
+       c(tgt.old.pctyoung, tgt.young.pctold, tgt.young.pctyoung),
+       c(target.b.w, target.h.w, target.o.w,
+         target.w.b, target.b.b, target.h.b, target.o.b,
+         target.w.h, target.b.h, target.h.h, target.o.h,
+         target.w.o, target.b.o, target.h.o, target.o.o),
+       c(negbin_inedges$n_nodes[c(indeg.terms+1)]),
+       c(outedges$n_nodes[c(deg.terms+1)]),
+       c(dist.nedge.distribution[dist.terms])
+     ),
+     eval.loglik = FALSE,
+     control = control.ergm(
+       #init = initial_coeffs,
+       MCMLE.maxit = 500,
+       main.method = c("Stochastic-Approximation"),
+       MCMC.interval = 1e6,
+       MCMC.samplesize = 1e6,
+       MCMLE.termination = "Hummel",
+       MCMC.effectiveSize=NULL,
+     #MPLE.samplesize = 50000, #MATCH ERGM3
+       SAN = control.san(
+       SAN.maxit = 500, 
+       SAN.nsteps = 1e8
+         #SAN.nsteps.times = 16
+                            )
+     )
+                            
+     )
Unable to match target stats. Using MCMLE estimation.
Starting maximum pseudolikelihood estimation (MPLE):
Obtaining the responsible dyads.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stochastic approximation algorithm with theta_0 equal to:
           edges      mix.sex.M.F      mix.sex.F.M      mix.sex.M.M 
     -8.90307077       1.15591620       0.94801623       1.09667879 
   mix.young.1.0    mix.young.0.1    mix.young.1.1 mix.race.num.2.1 
     -0.30131578      -0.99274446       0.31855799      -1.88261367 
mix.race.num.3.1 mix.race.num.4.1 mix.race.num.1.2 mix.race.num.2.2 
     -1.13341230      -0.61032696      -1.52250612       0.48411474 
mix.race.num.3.2 mix.race.num.4.2 mix.race.num.1.3 mix.race.num.2.3 
     -1.63405767      -2.07111505      -1.27476931      -1.29158555 
mix.race.num.3.3 mix.race.num.4.3 mix.race.num.1.4 mix.race.num.2.4 
     -0.01585616      -1.10597990      -0.48587105      -2.23842452 
mix.race.num.3.4 mix.race.num.4.4         idegree0         idegree1 
     -0.14552483       0.49855944       5.34350143       2.64973699 
        odegree0         odegree1         odegree2         odegree3 
      0.06693800      -1.11394781      -1.61674068      -1.23690746 
           dist1            dist2            dist3 
      6.53832937       2.69757646      -1.17082712 
Starting burnin of 16000000 steps
Phase 1: 200 steps (interval = 1000000)
Stochastic Approximation estimate:
           edges      mix.sex.M.F      mix.sex.F.M      mix.sex.M.M 
      -8.7391654        0.8620838        0.7714130        0.4392773 
   mix.young.1.0    mix.young.0.1    mix.young.1.1 mix.race.num.2.1 
      -0.4049589       -1.0277668        0.4286469       -1.6430087 
mix.race.num.3.1 mix.race.num.4.1 mix.race.num.1.2 mix.race.num.2.2 
      -1.1632871       -0.5524290       -1.6657074        0.3859030 
mix.race.num.3.2 mix.race.num.4.2 mix.race.num.1.3 mix.race.num.2.3 
      -1.6844798       -1.7107677       -1.1082041       -1.2752465 
mix.race.num.3.3 mix.race.num.4.3 mix.race.num.1.4 mix.race.num.2.4 
       0.4038442       -1.2607884       -0.4042164       -0.8539141 
mix.race.num.3.4 mix.race.num.4.4         idegree0         idegree1 
      -0.5789301        0.3951377        4.4791121        1.8617497 
        odegree0         odegree1         odegree2         odegree3 
      -0.3081491       -1.3226662       -1.2155534       -0.7968762 
           dist1            dist2            dist3 
       6.1100570        2.9518162       -1.0215107 
Phase 3:  1000 iterations (interval=1e+06)
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
>   
>   
> 
> save.image(file=here("fit-ergms", "out", "updated-with-oct12-2024-synthpop-ergmv4-6-all-plos1-mcmc-int1e6-samp1e6-hummel.RData"))RData"))
Error: unexpected symbol in "save.image(file=here("fit-ergms", "out", "updated-with-oct12-2024-synthpop-ergmv4-6-all-plos1-mcmc-int1e6-samp1e6-hummel.RData"))RData"
Execution halted
