
R version 4.4.0 (2024-04-24) -- "Puppy Cup"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

- Project '/oscar/home/akhann16/code/net-ergm-v4plus' loaded. [renv 1.0.7]
> # Analyze synthetic dataset with 32K nodes 
> 
> # Fit ERGM with 5 dyadic independent terms
> 
> rm(list=ls())
> 
> # Activate R environment ------------------------------
> 
> library(renv)

Attaching package: ‘renv’

The following objects are masked from ‘package:stats’:

    embed, update

The following objects are masked from ‘package:utils’:

    history, upgrade

The following objects are masked from ‘package:base’:

    autoload, load, remove, use

> renv::activate()
> 
> 
> # Libraries ----------
> 
> library(network)

‘network’ 1.18.2 (2023-12-04), part of the Statnet Project
* ‘news(package="network")’ for changes since last version
* ‘citation("network")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

> library(ergm)

‘ergm’ 4.6.0 (2023-12-17), part of the Statnet Project
* ‘news(package="ergm")’ for changes since last version
* ‘citation("ergm")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

‘ergm’ 4 is a major update that introduces some backwards-incompatible
changes. Please type ‘news(package="ergm")’ for a list of major
changes.

> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(ergm.userterms)
Loading required package: statnet.common

Attaching package: ‘statnet.common’

The following objects are masked from ‘package:base’:

    attr, order


‘ergm.userterms’ 3.1.1 (2020-02-01), part of the Statnet Project
* ‘news(package="ergm.userterms")’ for changes since last version
* ‘citation("ergm.userterms")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

NOTE: If you use custom ERGM terms based on ‘ergm.userterms’ version
prior to 3.1, you will need to perform a one-time update of the package
boilerplate files (the files that you did not write or modify) from
‘ergm.userterms’ 3.1 or later. See help('eut-upgrade') for
instructions.

> library(here)
here() starts at /oscar/home/akhann16/code/net-ergm-v4plus
> 
> 
> # Read Synthpop Data ------------------------------ 
> 
> data_path <- here("data", "synthpop-2023-10-12 12_01_32.csv")
> data <- read.csv(data_path, header=TRUE)
> glimpse(data)
Rows: 32,002
Columns: 15
$ sex                       <chr> "M", "M", "M", "M", "M", "M", "M", "M", "M",…
$ race                      <chr> "Wh", "Wh", "Wh", "Wh", "Wh", "Wh", "Wh", "W…
$ agecat                    <chr> "18-24", "18-24", "18-24", "18-24", "18-24",…
$ age_started               <int> 18, 19, 16, 19, 5, 19, 15, 17, 25, 18, 21, 1…
$ fraction_recept_sharing   <dbl> 1.00, 0.10, 0.10, 0.00, 0.00, 0.00, 0.25, 0.…
$ syringe_source            <int> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,…
$ daily_injection_intensity <chr> "once or twice a day", "once or twice a day"…
$ age_lb                    <int> 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, …
$ age_ub                    <int> 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, …
$ age                       <int> 23, 21, 19, 20, 21, 21, 21, 21, 25, 18, 24, …
$ zipcode                   <int> 60644, 60644, 60644, 60644, 60644, 60644, 60…
$ Zip                       <int> 60644, 60644, 60644, 60644, 60644, 60644, 60…
$ lon                       <dbl> -87.76885, -87.77289, -87.76898, -87.76998, …
$ lat                       <dbl> 41.88311, 41.88240, 41.86867, 41.89144, 41.8…
$ hcv_status                <chr> "sucseptible", "sucseptible", "sucseptible",…
> 
> # Input  In/Outdegree Data ------------------------------
> # (from networks simulated form the fit, as an alternate source of targets)
> 
> inedges <- read.csv(here("data", "pplrss.csv")) #in- and out-edges
> outedges <- read.csv(here("data", "ppldss.csv"))
> negbin_indeg <- read.csv(here("data", "negbin-indeg.csv"))
> negbin_outdeg <- read.csv(here("data", "negbin-outdeg.csv"))
> inedges.data <- read.csv(file = here("data", "inedges_data.csv"), header = TRUE)
> outedges.data <- read.csv(file = here("data", "outedges_data.csv"), header = TRUE)
> 
> # Input  Degree Distribution Data ------------------------------
> 
> #degree_distribution_target_stats <- 
>  # readRDS(here("simulate-from-ergms/out/degree_distribution_target_stats.RDS"))
> #names(degree_distribution_target_stats)
> 
>  
> 
> # Initialize network ----------
> 
> n <- nrow(data)
> n0 <- network.initialize(n = n, directed = TRUE)
> 
> 
> # Compute target number of edges ----------
> 
> inedges_target <- sum(inedges.data$k * inedges.data$nbprob * n)
> outedges_target <- sum(outedges.data$k * outedges.data$nbprob * n)
> edges_target <- mean(c(inedges_target, outedges_target))
> 
> 
> 
> 
> # Assign vertex attributes to the network ----------
> 
> synthpop_cols <- colnames(data)
> set.vertex.attribute(n0, colnames(data), data)
> 
> 
> # Test assignment between `n0` vertex attributes and `synthpop_cols` ----------
> 
> ## For sex variable
> identical(n0%v%"sex", data$sex)
[1] TRUE
> table(n0%v%"sex", exclude=NULL)

    F     M 
12573 19429 
> 
> ## For all variables:
> ### get vertex attribute names from the n0 graph object
> vertex_attr_names <- list.vertex.attributes(n0)
> 
> # define a function to check if a vertex attribute is identical to the corresponding column in data
> check_identical <- function(attr_name) {
+   graph_attr <- n0 %v% attr_name
+   data_attr <- data[[attr_name]]
+   
+   return(identical(graph_attr, data_attr))
+ }
> 
> ### use sapply() to apply the check_identical() function to all vertex attribute names
> identical_results <- sapply(vertex_attr_names, check_identical)
> 
> ### print the results
> print(identical_results)
                      age                    age_lb               age_started 
                     TRUE                      TRUE                      TRUE 
                   age_ub                    agecat daily_injection_intensity 
                     TRUE                      TRUE                      TRUE 
  fraction_recept_sharing                hcv_status                       lat 
                     TRUE                      TRUE                      TRUE 
                      lon                        na                      race 
                     TRUE                     FALSE                      TRUE 
                      sex            syringe_source              vertex.names 
                     TRUE                      TRUE                     FALSE 
                      Zip                   zipcode 
                     TRUE                      TRUE 
> 
> ### check if any values other than 'vertex.names' are FALSE
> if (any(identical_results[!(names(identical_results) %in% c("vertex.names", "na"))] == FALSE)) {
+   stop("Error: Some vertex attributes do not match the corresponding columns in data.")
+ } else {
+   cat("Test passed: All relevant vertex attributes match the corresponding columns in data.\n")
+ }
Test passed: All relevant vertex attributes match the corresponding columns in data.
> 
> 
> # Recode to add new variables to dataset ------------------------------
> 
> # young (< 26, to be set = 1) vs old (>= 26, to be set = 0) 
> age.cat <- n0 %v% "age"
> age.cat.df <- as.data.frame(age.cat)
> age.cat.df <-  
+   mutate(age.cat, young = ifelse(age.cat <26, 1, 0), .data = age.cat.df)
> xtabs(~age.cat+young, data = age.cat.df)
       young
age.cat    0    1
     18    0  471
     19    0  695
     20    0  854
     21    0 1053
     22    0 1142
     23    0 1286
     24    0 1561
     25    0  739
     26  787    0
     27  910    0
     28  946    0
     29 1018    0
     30 1024    0
     31 1027    0
     32 1119    0
     33 1110    0
     34 1117    0
     35  576    0
     36  585    0
     37  584    0
     38  617    0
     39  611    0
     40  676    0
     41  670    0
     42  732    0
     43  727    0
     44  719    0
     45  240    0
     46  232    0
     47  261    0
     48  253    0
     49  238    0
     50  225    0
     51  228    0
     52  233    0
     53  250    0
     54  235    0
     55  224    0
     56  231    0
     57  225    0
     58  269    0
     59  230    0
     60  258    0
     61  238    0
     62  245    0
     63  251    0
     64  252    0
     65  253    0
     66  212    0
     67  258    0
     68  231    0
     69  238    0
     70  229    0
     71  235    0
     72  219    0
     73  243    0
     74  263    0
     75  271    0
     76  243    0
     77  213    0
     78  256    0
     79  240    0
     80  224    0
> 
> # recode race variable to set ordering of categories
> race <- n0 %v% "race"
> race.num <- recode(race, 
+                    Wh = 1, Bl = 2,
+                    Hi = 3, Ot = 4)
> 
> # Initialize network and add attributes ----------
> 
> n0 %v% "young" <- age.cat.df$young
> n0 %v% "race.num" <- race.num
> 
> 
> # Generate target statistics from meta-mixing data ----------
> 
> ## gender 
> ### mixing information from meta-analysis of sathcap AND socnet
> edges.male.end <- mean(c(0.58, 0.59))
> edges.female.end <- mean(c(0.40, 0.41))
> 
> male.pctmale <- 0.53 
> male.pctfemale <- 0.47
> female.pctmale <- 0.75
> female.pctfemale <- 0.22
> 
> ### set gender targets 
> tgt.male.pctmale <- edges_target*edges.male.end*male.pctmale
> tgt.male.pctfemale <- edges_target*edges.male.end*male.pctfemale
> tgt.female.pctmale <- edges_target*edges.female.end*female.pctmale  
> tgt.female.pctfemale <- edges_target*edges.female.end*female.pctfemale
> 
> ## young (1=young; 0=old)
> ### mixing information from meta-analysis of sathcap AND socnet
> edges.young.end <- 0.10
> edges.old.end <- 0.90
>   
> young.pctyoung <- 0.60
> young.pctold <- 0.40
> old.pctyoung <- 0.14
> old.pctold <- 0.86
>  
> ## set young targets from meta data
> tgt.young.pctyoung <- edges_target * edges.young.end * young.pctyoung
> tgt.young.pctold <- edges_target * edges.young.end * young.pctold
> tgt.old.pctyoung <- edges_target * edges.old.end * old.pctyoung
> tgt.old.pctold <- edges_target * edges.old.end * old.pctold
> 
> 
> ## chicago
> ### mixing information from meta-analysis of sathcap AND socnet
> 
> edges.chicago.end <- 0.87
> edges.nonchicago.end <- 0.13
> 
> chicago.pctchicago <- 0.67
> chicago.pctnonchicago <- 0.30
> nonchicago.pctchicago <- 0.60
> nonchicago.pctnonchicago <- 0.40
> 
> 
> # ### mixing from simulation
> # chicago.mm <- mixingmatrix(sim, "chicago") #fem=1, chicago=2
> # from.nonchicago <- sum(chicago.mm$matrix[,1])
> # from.chicago <- sum(chicago.mm$matrix[,2])
> # 
> # ### set chicago targets from sathcap
> # tgt.chicago.pctchicago <- from.chicago*chicago.pctchicago
> # tgt.chicago.pctnonchicago <- from.chicago*chicago.pctnonchicago
> # tgt.nonchicago.pctchicago <- from.nonchicago*chicago.pctchicago
> # tgt.nonchicago.pctnonchicago <- from.nonchicago*chicago.pctnonchicago
> 
> 
> ## race (1=Black, 2=hispani,3=other, 4=white)
> 
> table(n0 %v% "race.num", exclude=NULL) # will be sorted as per 1=W, 2=B, 3=H, 4=O

    1     2     3     4 
15403  8317  6853  1429 
> 
> pct_to_white	<- mean(c(0.30, 0.31))
> pct_to_black	<- mean(c(0.41,	0.42))
> pct_to_hispanic	<- mean(c(0.21, 0.22))
> pct_to_other	<- mean(c(0.04,	0.05))
> 
> race.w.w <- 0.73
> race.b.w <- 0.10
> race.h.w <- 0.12
> race.o.w <- 0.04
> race.w.b <- 0.10
> race.b.b <- 0.83
> race.h.b <- 0.06
> race.o.b <- 0.01
> race.w.h <- 0.21
> race.b.h <- 0.15
> race.h.h <- 0.62
> race.o.h <- 0.02
> race.w.o <- 0.43
> race.b.o <- 0.21
> race.h.o <- 0.22
> race.o.o <- 0.14
> 
> target.w.w <- edges_target * pct_to_white * race.w.w
> target.b.w <- edges_target * pct_to_white * race.b.w
> target.h.w <- edges_target * pct_to_white * race.h.w
> target.o.w <- edges_target * pct_to_white * race.o.w
> 
> target.w.b <- edges_target * pct_to_black * race.w.b
> target.b.b <- edges_target * pct_to_black * race.b.b
> target.h.b <- edges_target * pct_to_black * race.h.b
> target.o.b <- edges_target * pct_to_black * race.o.b
> 
> target.w.h <- edges_target * pct_to_hispanic * race.w.h
> target.b.h <- edges_target * pct_to_hispanic * race.b.h
> target.h.h <- edges_target * pct_to_hispanic * race.h.h
> target.o.h <- edges_target * pct_to_hispanic * race.o.h
> 
> target.w.o <- edges_target * pct_to_other * race.w.o
> target.b.o <- edges_target * pct_to_other * race.b.o
> target.h.o <- edges_target * pct_to_other * race.h.o
> target.o.o <- edges_target * pct_to_other * race.o.o
> 
> ## degree distributions
> inedges <- inedges %>% 
+   mutate(n_nodes = n*nbprob)
> outedges <- outedges %>% 
+   mutate(n_nodes = n*nbprob)
> 
> negbin_inedges <- negbin_indeg %>% 
+   mutate(n_nodes = n*nbprob)
> negbin_outedges <- negbin_outdeg %>% 
+   mutate(n_nodes = n*nbprob)
> 
> ## distance term
> 
> dist.prop.distribution <- c(15.7, 35.1, 24.1, 22)/100
> dist.nedge.distribution <- edges_target*dist.prop.distribution
> 
> # Fit ERGM (with SATHCAP mixing) ----------
> 
> deg.terms <- 0:3
> indeg.terms <- 0:1  
> 
> dist.terms <- 1:3 #fourth is left out
> #dist.terms <- 3 #only try the third term
> 
> # Specify initial coefs ----------
> 
> initial_coeffs <- c("edges" = -9.319, 
+                     "mix.race.num.4.1" = 0.16349, 
+                     "odegree0" = -0.1386842, 
+                     "mix.race.num.2.4" = 0.13625, 
+                     "mix.race.num.4.4" = 0.20408)
> 
> fit_nonemmpty_network <- 
+   ergm(
+     n0 ~
+       edges + 
+       nodemix("sex", levels2=-1)+
+       nodemix("young", levels2=-1),
+     target.stats = 
+     c(
+       edges_target,
+       c(tgt.female.pctmale, tgt.male.pctfemale, tgt.male.pctmale),
+       c(tgt.old.pctyoung, tgt.young.pctold, tgt.young.pctyoung)      
+     ),
+     eval.loglik = FALSE    
+     )
Unable to match target stats. Using MCMLE estimation.
Starting maximum pseudolikelihood estimation (MPLE):
Obtaining the responsible dyads.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Starting Monte Carlo maximum likelihood estimation (MCMLE):
Iteration 1 of at most 60:
Optimizing with step length 0.4695.
The log-likelihood improved by 2.7416.
Estimating equations are not within tolerance region.
Iteration 2 of at most 60:
Optimizing with step length 0.8930.
The log-likelihood improved by 1.9615.
Estimating equations are not within tolerance region.
Iteration 3 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.1117.
Estimating equations are not within tolerance region.
Iteration 4 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0277.
Convergence test p-value: 0.7141. Not converged with 99% confidence; increasing sample size.
Iteration 5 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0507.
Convergence test p-value: 0.1010. Not converged with 99% confidence; increasing sample size.
Iteration 6 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0386.
Convergence test p-value: 0.0638. Not converged with 99% confidence; increasing sample size.
Iteration 7 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0168.
Convergence test p-value: 0.0104. Not converged with 99% confidence; increasing sample size.
Iteration 8 of at most 60:
Optimizing with step length 1.0000.
The log-likelihood improved by 0.0130.
Convergence test p-value: 0.0044. Converged with 99% confidence.
Finished MCMLE.
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
>   
> 
> non_empty_net <- simulate(fit_nonemmpty_network, nsim=1)
> 
> fit.metadata.mixing <-
+   ergm(
+     non_empty_net ~
+       edges + 
+       nodemix("sex", levels2=-1)+
+       nodemix("young", levels2=-1)+
+       nodemix("race.num", levels2=-1)+
+       idegree(indeg.terms)+
+       odegree(deg.terms)+
+       dist(dist.terms),
+     target.stats = 
+     c(
+       edges_target,
+       c(tgt.female.pctmale, tgt.male.pctfemale, tgt.male.pctmale),           
+       c(tgt.old.pctyoung, tgt.young.pctold, tgt.young.pctyoung),
+       c(target.b.w, target.h.w, target.o.w,
+         target.w.b, target.b.b, target.h.b, target.o.b,
+         target.w.h, target.b.h, target.h.h, target.o.h,
+         target.w.o, target.b.o, target.h.o, target.o.o),
+       c(negbin_inedges$n_nodes[c(indeg.terms+1)]),
+       c(outedges$n_nodes[c(deg.terms+1)]),
+       c(dist.nedge.distribution[dist.terms])
+     ),
+     eval.loglik = FALSE,
+     control = control.ergm(
+       MCMLE.maxit = 500,  
+       main.method = c("Stochastic-Approximation"),
+       MCMC.interval = 1e6,
+       MCMC.samplesize = 1e6,
+       MCMLE.termination = "Hotelling",
+       MCMC.effectiveSize=NULL,
+     #MPLE.samplesize = 50000, #MATCH ERGM3
+       SAN = control.san(
+       SAN.maxit = 500, 
+       SAN.nsteps = 1e8
+         #SAN.nsteps.times = 16
+                            )
+     )
+                            
+     )
Unable to match target stats. Using MCMLE estimation.
Starting maximum pseudolikelihood estimation (MPLE):
Obtaining the responsible dyads.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stochastic approximation algorithm with theta_0 equal to:
           edges      mix.sex.M.F      mix.sex.F.M      mix.sex.M.M 
      -8.6118538        1.0414903        0.8088538        0.2880667 
   mix.young.1.0    mix.young.0.1    mix.young.1.1 mix.race.num.2.1 
      -0.7532194       -0.9667647        0.4975376       -1.9862869 
mix.race.num.3.1 mix.race.num.4.1 mix.race.num.1.2 mix.race.num.2.2 
      -1.4237323       -0.2973129       -2.1604210        0.3393903 
mix.race.num.3.2 mix.race.num.4.2 mix.race.num.1.3 mix.race.num.2.3 
      -1.6025358       -1.3221625       -1.0276164       -1.5573632 
mix.race.num.3.3 mix.race.num.4.3 mix.race.num.1.4 mix.race.num.2.4 
       0.3503002       -0.3889387       -0.5124550       -0.4087331 
mix.race.num.3.4 mix.race.num.4.4         idegree0         idegree1 
      -0.7874958        0.4557356        5.7810888        2.9467650 
        odegree0         odegree1         odegree2         odegree3 
      -1.1068061       -2.2631460       -2.1879676       -1.5940702 
           dist1            dist2            dist3 
       7.5176794        2.9019085       -1.2699513 
Starting burnin of 16000000 steps
Phase 1: 200 steps (interval = 1000000)
Stochastic Approximation estimate:
           edges      mix.sex.M.F      mix.sex.F.M      mix.sex.M.M 
      -8.6440927        0.8776100        0.7572149        0.3291612 
   mix.young.1.0    mix.young.0.1    mix.young.1.1 mix.race.num.2.1 
      -0.5630430       -1.0991455        0.4183393       -1.9619876 
mix.race.num.3.1 mix.race.num.4.1 mix.race.num.1.2 mix.race.num.2.2 
      -1.4624824       -0.8435311       -2.0192198        0.2415388 
mix.race.num.3.2 mix.race.num.4.2 mix.race.num.1.3 mix.race.num.2.3 
      -2.1579463       -2.1685295       -1.3881563       -1.6283931 
mix.race.num.3.3 mix.race.num.4.3 mix.race.num.1.4 mix.race.num.2.4 
       0.1946514       -1.7104720       -0.6354156       -1.1284385 
mix.race.num.3.4 mix.race.num.4.4         idegree0         idegree1 
      -0.8830130       -0.1024751        5.5777684        2.7625320 
        odegree0         odegree1         odegree2         odegree3 
      -1.0551197       -1.8033321       -1.5134817       -1.0240645 
           dist1            dist2            dist3 
       7.0169536        2.8856566       -1.0217816 
Phase 3:  1000 iterations (interval=1e+06)
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
>   
>   
> 
> save.image(file=here("fit-ergms", "out", "non-empty-net-all-plos1-mcmc-int1e6-samp1e6-hotelling.RData"))  
> 
> proc.time()
    user   system  elapsed 
1220.938   29.891 1260.774 
