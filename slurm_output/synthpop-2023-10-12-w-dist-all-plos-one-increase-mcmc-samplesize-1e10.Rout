
R version 4.4.0 (2024-04-24) -- "Puppy Cup"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

- Project '/oscar/home/akhann16/code/net-ergm-v4plus' loaded. [renv 1.0.7]
> # Analyze synthetic dataset with 32K nodes 
> 
> # Fit ERGM with 5 dyadic independent terms
> 
> rm(list=ls())
> 
> # Activate R environment ------------------------------
> 
> library(renv)

Attaching package: ‘renv’

The following objects are masked from ‘package:stats’:

    embed, update

The following objects are masked from ‘package:utils’:

    history, upgrade

The following objects are masked from ‘package:base’:

    autoload, load, remove, use

> renv::activate()
> 
> 
> # Libraries ----------
> 
> library(network)

‘network’ 1.18.2 (2023-12-04), part of the Statnet Project
* ‘news(package="network")’ for changes since last version
* ‘citation("network")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

> library(ergm)

‘ergm’ 4.6.0 (2023-12-17), part of the Statnet Project
* ‘news(package="ergm")’ for changes since last version
* ‘citation("ergm")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

‘ergm’ 4 is a major update that introduces some backwards-incompatible
changes. Please type ‘news(package="ergm")’ for a list of major
changes.

> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(ergm.userterms)
Loading required package: statnet.common

Attaching package: ‘statnet.common’

The following objects are masked from ‘package:base’:

    attr, order


‘ergm.userterms’ 3.1.1 (2020-02-01), part of the Statnet Project
* ‘news(package="ergm.userterms")’ for changes since last version
* ‘citation("ergm.userterms")’ for citation information
* ‘https://statnet.org’ for help, support, and other information

NOTE: If you use custom ERGM terms based on ‘ergm.userterms’ version
prior to 3.1, you will need to perform a one-time update of the package
boilerplate files (the files that you did not write or modify) from
‘ergm.userterms’ 3.1 or later. See help('eut-upgrade') for
instructions.

> library(here)
here() starts at /oscar/home/akhann16/code/net-ergm-v4plus
> 
> 
> # Read Synthpop Data ------------------------------ 
> 
> data_path <- here("data", "synthpop-2023-10-12 12_01_32.csv")
> data <- read.csv(data_path, header=TRUE)
> glimpse(data)
Rows: 32,002
Columns: 15
$ sex                       <chr> "M", "M", "M", "M", "M", "M", "M", "M", "M",…
$ race                      <chr> "Wh", "Wh", "Wh", "Wh", "Wh", "Wh", "Wh", "W…
$ agecat                    <chr> "18-24", "18-24", "18-24", "18-24", "18-24",…
$ age_started               <int> 18, 19, 16, 19, 5, 19, 15, 17, 25, 18, 21, 1…
$ fraction_recept_sharing   <dbl> 1.00, 0.10, 0.10, 0.00, 0.00, 0.00, 0.25, 0.…
$ syringe_source            <int> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,…
$ daily_injection_intensity <chr> "once or twice a day", "once or twice a day"…
$ age_lb                    <int> 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, …
$ age_ub                    <int> 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, …
$ age                       <int> 23, 21, 19, 20, 21, 21, 21, 21, 25, 18, 24, …
$ zipcode                   <int> 60644, 60644, 60644, 60644, 60644, 60644, 60…
$ Zip                       <int> 60644, 60644, 60644, 60644, 60644, 60644, 60…
$ lon                       <dbl> -87.76885, -87.77289, -87.76898, -87.76998, …
$ lat                       <dbl> 41.88311, 41.88240, 41.86867, 41.89144, 41.8…
$ hcv_status                <chr> "sucseptible", "sucseptible", "sucseptible",…
> 
> # Input  In/Outdegree Data ------------------------------
> # (from networks simulated form the fit, as an alternate source of targets)
> 
> inedges <- read.csv(here("data", "pplrss.csv")) #in- and out-edges
> outedges <- read.csv(here("data", "ppldss.csv"))
> negbin_indeg <- read.csv(here("data", "negbin-indeg.csv"))
> negbin_outdeg <- read.csv(here("data", "negbin-outdeg.csv"))
> inedges.data <- read.csv(file = here("data", "inedges_data.csv"), header = TRUE)
> outedges.data <- read.csv(file = here("data", "outedges_data.csv"), header = TRUE)
> 
> # Input  Degree Distribution Data ------------------------------
> 
> #degree_distribution_target_stats <- 
>  # readRDS(here("simulate-from-ergms/out/degree_distribution_target_stats.RDS"))
> #names(degree_distribution_target_stats)
> 
>  
> 
> # Initialize network ----------
> 
> n <- nrow(data)
> n0 <- network.initialize(n = n, directed = TRUE)
> 
> 
> # Compute target number of edges ----------
> 
> inedges_target <- sum(inedges.data$k * inedges.data$nbprob * n)
> outedges_target <- sum(outedges.data$k * outedges.data$nbprob * n)
> edges_target <- mean(c(inedges_target, outedges_target))
> 
> 
> 
> 
> # Assign vertex attributes to the network ----------
> 
> synthpop_cols <- colnames(data)
> set.vertex.attribute(n0, colnames(data), data)
> 
> 
> # Test assignment between `n0` vertex attributes and `synthpop_cols` ----------
> 
> ## For sex variable
> identical(n0%v%"sex", data$sex)
[1] TRUE
> table(n0%v%"sex", exclude=NULL)

    F     M 
12573 19429 
> 
> ## For all variables:
> ### get vertex attribute names from the n0 graph object
> vertex_attr_names <- list.vertex.attributes(n0)
> 
> # define a function to check if a vertex attribute is identical to the corresponding column in data
> check_identical <- function(attr_name) {
+   graph_attr <- n0 %v% attr_name
+   data_attr <- data[[attr_name]]
+   
+   return(identical(graph_attr, data_attr))
+ }
> 
> ### use sapply() to apply the check_identical() function to all vertex attribute names
> identical_results <- sapply(vertex_attr_names, check_identical)
> 
> ### print the results
> print(identical_results)
                      age                    age_lb               age_started 
                     TRUE                      TRUE                      TRUE 
                   age_ub                    agecat daily_injection_intensity 
                     TRUE                      TRUE                      TRUE 
  fraction_recept_sharing                hcv_status                       lat 
                     TRUE                      TRUE                      TRUE 
                      lon                        na                      race 
                     TRUE                     FALSE                      TRUE 
                      sex            syringe_source              vertex.names 
                     TRUE                      TRUE                     FALSE 
                      Zip                   zipcode 
                     TRUE                      TRUE 
> 
> ### check if any values other than 'vertex.names' are FALSE
> if (any(identical_results[!(names(identical_results) %in% c("vertex.names", "na"))] == FALSE)) {
+   stop("Error: Some vertex attributes do not match the corresponding columns in data.")
+ } else {
+   cat("Test passed: All relevant vertex attributes match the corresponding columns in data.\n")
+ }
Test passed: All relevant vertex attributes match the corresponding columns in data.
> 
> 
> # Recode to add new variables to dataset ------------------------------
> 
> # young (< 26, to be set = 1) vs old (>= 26, to be set = 0) 
> age.cat <- n0 %v% "age"
> age.cat.df <- as.data.frame(age.cat)
> age.cat.df <-  
+   mutate(age.cat, young = ifelse(age.cat <26, 1, 0), .data = age.cat.df)
> xtabs(~age.cat+young, data = age.cat.df)
       young
age.cat    0    1
     18    0  471
     19    0  695
     20    0  854
     21    0 1053
     22    0 1142
     23    0 1286
     24    0 1561
     25    0  739
     26  787    0
     27  910    0
     28  946    0
     29 1018    0
     30 1024    0
     31 1027    0
     32 1119    0
     33 1110    0
     34 1117    0
     35  576    0
     36  585    0
     37  584    0
     38  617    0
     39  611    0
     40  676    0
     41  670    0
     42  732    0
     43  727    0
     44  719    0
     45  240    0
     46  232    0
     47  261    0
     48  253    0
     49  238    0
     50  225    0
     51  228    0
     52  233    0
     53  250    0
     54  235    0
     55  224    0
     56  231    0
     57  225    0
     58  269    0
     59  230    0
     60  258    0
     61  238    0
     62  245    0
     63  251    0
     64  252    0
     65  253    0
     66  212    0
     67  258    0
     68  231    0
     69  238    0
     70  229    0
     71  235    0
     72  219    0
     73  243    0
     74  263    0
     75  271    0
     76  243    0
     77  213    0
     78  256    0
     79  240    0
     80  224    0
> 
> # recode race variable to set ordering of categories
> race <- n0 %v% "race"
> race.num <- recode(race, 
+                    Wh = 1, Bl = 2,
+                    Hi = 3, Ot = 4)
> 
> # Initialize network and add attributes ----------
> 
> n0 %v% "young" <- age.cat.df$young
> n0 %v% "race.num" <- race.num
> 
> 
> # Generate target statistics from meta-mixing data ----------
> 
> ## gender 
> ### mixing information from meta-analysis of sathcap AND socnet
> edges.male.end <- mean(c(0.58, 0.59))
> edges.female.end <- mean(c(0.40, 0.41))
> 
> male.pctmale <- 0.53 
> male.pctfemale <- 0.47
> female.pctmale <- 0.75
> female.pctfemale <- 0.22
> 
> ### set gender targets 
> tgt.male.pctmale <- edges_target*edges.male.end*male.pctmale
> tgt.male.pctfemale <- edges_target*edges.male.end*male.pctfemale
> tgt.female.pctmale <- edges_target*edges.female.end*female.pctmale  
> tgt.female.pctfemale <- edges_target*edges.female.end*female.pctfemale
> 
> ## young (1=young; 0=old)
> ### mixing information from meta-analysis of sathcap AND socnet
> edges.young.end <- 0.10
> edges.old.end <- 0.90
>   
> young.pctyoung <- 0.60
> young.pctold <- 0.40
> old.pctyoung <- 0.14
> old.pctold <- 0.86
>  
> ## set young targets from meta data
> tgt.young.pctyoung <- edges_target * edges.young.end * young.pctyoung
> tgt.young.pctold <- edges_target * edges.young.end * young.pctold
> tgt.old.pctyoung <- edges_target * edges.old.end * old.pctyoung
> tgt.old.pctold <- edges_target * edges.old.end * old.pctold
> 
> 
> ## chicago
> ### mixing information from meta-analysis of sathcap AND socnet
> 
> edges.chicago.end <- 0.87
> edges.nonchicago.end <- 0.13
> 
> chicago.pctchicago <- 0.67
> chicago.pctnonchicago <- 0.30
> nonchicago.pctchicago <- 0.60
> nonchicago.pctnonchicago <- 0.40
> 
> 
> # ### mixing from simulation
> # chicago.mm <- mixingmatrix(sim, "chicago") #fem=1, chicago=2
> # from.nonchicago <- sum(chicago.mm$matrix[,1])
> # from.chicago <- sum(chicago.mm$matrix[,2])
> # 
> # ### set chicago targets from sathcap
> # tgt.chicago.pctchicago <- from.chicago*chicago.pctchicago
> # tgt.chicago.pctnonchicago <- from.chicago*chicago.pctnonchicago
> # tgt.nonchicago.pctchicago <- from.nonchicago*chicago.pctchicago
> # tgt.nonchicago.pctnonchicago <- from.nonchicago*chicago.pctnonchicago
> 
> 
> ## race (1=Black, 2=hispani,3=other, 4=white)
> 
> table(n0 %v% "race.num", exclude=NULL) # will be sorted as per 1=W, 2=B, 3=H, 4=O

    1     2     3     4 
15403  8317  6853  1429 
> 
> pct_to_white	<- mean(c(0.30, 0.31))
> pct_to_black	<- mean(c(0.41,	0.42))
> pct_to_hispanic	<- mean(c(0.21, 0.22))
> pct_to_other	<- mean(c(0.04,	0.05))
> 
> race.w.w <- 0.73
> race.b.w <- 0.10
> race.h.w <- 0.12
> race.o.w <- 0.04
> race.w.b <- 0.10
> race.b.b <- 0.83
> race.h.b <- 0.06
> race.o.b <- 0.01
> race.w.h <- 0.21
> race.b.h <- 0.15
> race.h.h <- 0.62
> race.o.h <- 0.02
> race.w.o <- 0.43
> race.b.o <- 0.21
> race.h.o <- 0.22
> race.o.o <- 0.14
> 
> target.w.w <- edges_target * pct_to_white * race.w.w
> target.b.w <- edges_target * pct_to_white * race.b.w
> target.h.w <- edges_target * pct_to_white * race.h.w
> target.o.w <- edges_target * pct_to_white * race.o.w
> 
> target.w.b <- edges_target * pct_to_black * race.w.b
> target.b.b <- edges_target * pct_to_black * race.b.b
> target.h.b <- edges_target * pct_to_black * race.h.b
> target.o.b <- edges_target * pct_to_black * race.o.b
> 
> target.w.h <- edges_target * pct_to_hispanic * race.w.h
> target.b.h <- edges_target * pct_to_hispanic * race.b.h
> target.h.h <- edges_target * pct_to_hispanic * race.h.h
> target.o.h <- edges_target * pct_to_hispanic * race.o.h
> 
> target.w.o <- edges_target * pct_to_other * race.w.o
> target.b.o <- edges_target * pct_to_other * race.b.o
> target.h.o <- edges_target * pct_to_other * race.h.o
> target.o.o <- edges_target * pct_to_other * race.o.o
> 
> ## degree distributions
> inedges <- inedges %>% 
+   mutate(n_nodes = n*nbprob)
> outedges <- outedges %>% 
+   mutate(n_nodes = n*nbprob)
> 
> negbin_inedges <- negbin_indeg %>% 
+   mutate(n_nodes = n*nbprob)
> negbin_outedges <- negbin_outdeg %>% 
+   mutate(n_nodes = n*nbprob)
> 
> ## distance term
> 
> dist.prop.distribution <- c(15.7, 35.1, 24.1, 22)/100
> dist.nedge.distribution <- edges_target*dist.prop.distribution
> 
> # Fit ERGM (with SATHCAP mixing) ----------
> 
> deg.terms <- 0:3
> indeg.terms <- 0:1  
> 
> dist.terms <- 1:3 #fourth is left out
> 
> 
> fit.metadata.mixing <-
+   ergm(
+     n0 ~
+       edges+
+       nodemix("sex", levels2=-1)+
+       nodemix("young", levels2=-1)+
+       nodemix("race.num", levels2=-1)+
+       idegree(indeg.terms)+
+       odegree(deg.terms)+
+       dist(dist.terms),
+     target.stats = 
+     c(
+       edges_target,
+       c(tgt.female.pctmale, tgt.male.pctfemale, tgt.male.pctmale),           
+       c(tgt.old.pctyoung, tgt.young.pctold, tgt.young.pctyoung),
+       c(target.b.w, target.h.w, target.o.w,
+         target.w.b, target.b.b, target.h.b, target.o.b,
+         target.w.h, target.b.h, target.h.h, target.o.h,
+         target.w.o, target.b.o, target.h.o, target.o.o),
+       c(negbin_inedges$n_nodes[c(indeg.terms+1)]),
+       c(outedges$n_nodes[c(deg.terms+1)]),
+       c(dist.nedge.distribution[dist.terms])
+     ),
+     eval.loglik = FALSE,
+     control = control.ergm(MCMLE.maxit = 500,
+                            main.method = c("Stochastic-Approximation"),
+                            MCMC.interval = 1e5,
+                            MCMC.samplesize = 1e10,
+                           #MPLE.samplesize = 50000, #MATCH ERGM3
+                            SAN = control.san(
+                              SAN.maxit = 500, 
+                              SAN.nsteps = 1e8
+                              #SAN.nsteps.times = 16
+                            )
+     )
+                            
+     )
Unable to match target stats. Using MCMLE estimation.
Starting maximum pseudolikelihood estimation (MPLE):
Obtaining the responsible dyads.
Evaluating the predictor and response matrix.
Maximizing the pseudolikelihood.
Finished MPLE.
Stochastic approximation algorithm with theta_0 equal to:
           edges      mix.sex.M.F      mix.sex.F.M      mix.sex.M.M 
     -9.01709914       1.16356631       1.05831978       0.60318250 
   mix.young.1.0    mix.young.0.1    mix.young.1.1 mix.race.num.2.1 
     -0.84895474      -1.24894080       0.62324669      -1.43004965 
mix.race.num.3.1 mix.race.num.4.1 mix.race.num.1.2 mix.race.num.2.2 
     -1.27320381      -0.53473948      -1.53366006       0.50235416 
mix.race.num.3.2 mix.race.num.4.2 mix.race.num.1.3 mix.race.num.2.3 
     -1.93703362      -1.04811177      -1.42292886      -2.37006526 
mix.race.num.3.3 mix.race.num.4.3 mix.race.num.1.4 mix.race.num.2.4 
     -0.36446346      -4.04070732      -0.01012903      -0.81328221 
mix.race.num.3.4 mix.race.num.4.4         idegree0         idegree1 
     -0.20093262       1.48048977       4.59826275       1.68878240 
        odegree0         odegree1         odegree2         odegree3 
     -1.89487658      -2.81168992      -2.53658458      -1.88760451 
           dist1            dist2            dist3 
      7.65446308       3.02588690      -1.24159588 
Starting burnin of 1600000 steps
Phase 1: 200 steps (interval = 100000)
Stochastic Approximation estimate:
           edges      mix.sex.M.F      mix.sex.F.M      mix.sex.M.M 
      -9.0277262        1.1318996        1.0229099        0.5651474 
   mix.young.1.0    mix.young.0.1    mix.young.1.1 mix.race.num.2.1 
      -0.9192554       -1.3770007        0.5783033       -1.6554089 
mix.race.num.3.1 mix.race.num.4.1 mix.race.num.1.2 mix.race.num.2.2 
      -1.4886885       -0.8301167       -1.8915948        0.4252017 
mix.race.num.3.2 mix.race.num.4.2 mix.race.num.1.3 mix.race.num.2.3 
      -2.2024601       -2.0711229       -1.1685547       -1.4459060 
mix.race.num.3.3 mix.race.num.4.3 mix.race.num.1.4 mix.race.num.2.4 
       0.4378848       -1.4255064       -0.1900941       -1.4237028 
mix.race.num.3.4 mix.race.num.4.4         idegree0         idegree1 
      -0.7842016        1.0303497        4.7131218        1.9850725 
        odegree0         odegree1         odegree2         odegree3 
      -1.8343749       -2.7173985       -2.2970325       -2.1456190 
           dist1            dist2            dist3 
       6.3165064        2.9589641       -1.2780226 
Phase 3:  1000 iterations (interval=1e+05)
This model was fit using MCMC.  To examine model diagnostics and check
for degeneracy, use the mcmc.diagnostics() function.
>   
>   
> 
> save.image(file=here("fit-ergms", "out", "updated-with-oct12-2024-synthpop-ergmv4-6-all-plosone-terms-increase-mcmc-samplesize-1e10.RData"))
> 
> proc.time()
   user  system elapsed 
364.863  22.985 390.580 
